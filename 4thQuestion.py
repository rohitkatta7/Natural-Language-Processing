# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WgbnuKxEy213gKQHtNK1eMdRz9GGyr4i
"""



from google.colab import drive
drive.mount('/content/drive')

import os
import spacy
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

# Load the English tokenizer, tagger, parser, NER, and word vectors
nlp = spacy.load("en_core_web_sm")

# Function to extract adjectives from documents in a given folder
def extract_adjectives(folder_path):
    adjectives = set()
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, 'r') as file:
            content = file.read()
            doc = nlp(content)
            for token in doc:
                if token.pos_ == 'ADJ':  # If the token is an adjective
                    adjectives.add(token.lemma_.lower())  # Add its lemma to the set
    return adjectives

# Function to create bag-of-word binary features for documents in a given folder
def create_feature_vectors(folder_path, vocabulary):
    feature_vectors = []
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, 'r') as file:
            content = file.read()
            doc = nlp(content)
            document_adjectives = set(token.lemma_.lower() for token in doc if token.pos_ == 'ADJ')
            feature_vector = [1 if adjective in document_adjectives else 0 for adjective in vocabulary]
            feature_vectors.append(feature_vector)
    return np.array(feature_vectors)

# Paths to the folders
pos_train_folder = "/content/drive/MyDrive/pos_train"
neg_train_folder = "/content/drive/MyDrive/neg_train"
pos_test_folder = "/content/drive/MyDrive/pos_test"
neg_test_folder = "/content/drive/MyDrive/neg_test"

# Extract adjectives from the positive and negative training sets
pos_adjectives = extract_adjectives(pos_train_folder)
neg_adjectives = extract_adjectives(neg_train_folder)

# Combine the adjectives from both sets to form the complete vocabulary
adjective_vocabulary = list(pos_adjectives.union(neg_adjectives))

# Create feature vectors for the training sets
pos_feature_vectors = create_feature_vectors(pos_train_folder, adjective_vocabulary)
neg_feature_vectors = create_feature_vectors(neg_train_folder, adjective_vocabulary)

# Combine the positive and negative feature vectors and labels for training
X_train = np.vstack((pos_feature_vectors, neg_feature_vectors))
y_train = np.array([1] * len(pos_feature_vectors) + [0] * len(neg_feature_vectors))

# Initialize and train the logistic regression model
model = LogisticRegression(solver='liblinear')  # Using 'liblinear' solver for binary classification
model.fit(X_train, y_train)

# Create feature vectors for the test sets
pos_feature_vectors_test = create_feature_vectors(pos_test_folder, adjective_vocabulary)
neg_feature_vectors_test = create_feature_vectors(neg_test_folder, adjective_vocabulary)

# Combine the positive and negative feature vectors and labels for testing
X_test = np.vstack((pos_feature_vectors_test, neg_feature_vectors_test))
y_test = np.array([1] * len(pos_feature_vectors_test) + [0] * len(neg_feature_vectors_test))

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate the F1 score
f1 = f1_score(y_test, y_pred)

# Output the size of the vocabulary and some examples
print(f"Size of adjective vocabulary: {len(adjective_vocabulary)}")
print(f"Some examples of adjectives: {adjective_vocabulary[:10]}")
print(f"Shape of positive feature vectors: {pos_feature_vectors.shape}")
print(f"Shape of negative feature vectors: {neg_feature_vectors.shape}")
print(f"Training accuracy: {model.score(X_train, y_train)}")
print(f"F1 score on the test set: {f1}")